{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweepy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1fL0F4jIlUaOxeowC1VmFRII99UIy--WR",
      "authorship_tag": "ABX9TyOQ/DXNE+zK4nvP4XOkJ3FM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreeyaKokate/Twitter-Analysis/blob/main/Tweepy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx1T7E8dphos"
      },
      "source": [
        "import tweepy\n",
        "from tweepy import Cursor\n",
        "from datetime import datetime, date, time\n",
        "import json\n",
        "import pandas as pd\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import matplotlib as mpl\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import operator\n",
        "from textblob import TextBlob\n",
        "from textblob import Word\n",
        "from textblob.sentiments import NaiveBayesAnalyzer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyGGmHpnppuQ"
      },
      "source": [
        "#Authentication\n",
        "consumer_key = '5k6YW9hGYcmjZQKA3SgV8WaKj'\n",
        "consumer_secret = 'qiFWNQHwakkZiWlRIaDfd05zq7hJ6d8T4TLLAi08ylRhZwNizx'\n",
        "access_key = '1082654918987694083-DhNd1zerKLI5lvlTdCaTIhkK8Xm1gA'\n",
        "access_secret = 'CHYHMUm7wwdfnYPZzbpfsTo9BMvk9nMIwga0pqChJG1aM'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) #Interacting with twitter's API\n",
        "auth.set_access_token(access_key, access_secret)\n",
        "api = tweepy.API (auth) #creating the API object\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfmo8ViDqMiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74dabcd6-9d21-48cb-b9af-9e12bb55405c"
      },
      "source": [
        "#Extracting Tweets\n",
        "results = []\n",
        "for tweet in tweepy.Cursor (api.search, q='Black Lives Matter', lang = \"en\").items(2000): \n",
        "    results.append(tweet)\n",
        "    \n",
        "print (type(results))\n",
        "print (len(results))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ67zoyGqW_M"
      },
      "source": [
        "#Store tweets data in a dataframe\n",
        "\n",
        "def tweets_df(results):\n",
        "    id_list = [tweet.id for tweet  in results]\n",
        "    data_set = pd.DataFrame(id_list, columns = [\"id\"])\n",
        "    \n",
        "    data_set[\"text\"] = [tweet.text for tweet in results]\n",
        "    data_set[\"created_at\"] = [tweet.created_at for tweet in results]\n",
        "    data_set[\"retweet_count\"] = [tweet.retweet_count for tweet in results]\n",
        "    data_set[\"user_screen_name\"] = [tweet.author.screen_name for tweet in results]\n",
        "    data_set[\"user_followers_count\"] = [tweet.author.followers_count for tweet in results]\n",
        "    data_set[\"user_location\"] = [tweet.author.location for tweet in results]\n",
        "    data_set[\"Hashtags\"] = [tweet.entities.get('hashtags') for tweet in results]\n",
        "    \n",
        "    return data_set\n",
        "data_set = tweets_df(results)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXpBG3nzxURA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb26d8c-86e4-48cd-d6cd-b248ca92efd9"
      },
      "source": [
        "print(data_set)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                       id  ...                                           Hashtags\n",
            "0     1351434471522914310  ...                                                 []\n",
            "1     1351434422390648833  ...                                                 []\n",
            "2     1351434413070958592  ...  [{'text': 'PS5Share', 'indices': [37, 46]}, {'...\n",
            "3     1351434355873341442  ...                                                 []\n",
            "4     1351434338957627394  ...                                                 []\n",
            "...                   ...  ...                                                ...\n",
            "1995  1351388831220600832  ...             [{'text': 'OtD', 'indices': [21, 25]}]\n",
            "1996  1351388810790187008  ...                                                 []\n",
            "1997  1351388804486197251  ...                                                 []\n",
            "1998  1351388773112827904  ...                                                 []\n",
            "1999  1351388765785362433  ...                                                 []\n",
            "\n",
            "[2000 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8i3bhJ3ypMt"
      },
      "source": [
        "data_set.to_csv(\"/content/drive/MyDrive/Colab Notebooks/BLM1.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjr22YpSt7WP"
      },
      "source": [
        "# Remove tweets with duplicate text\n",
        "\n",
        "text = data_set[\"text\"]\n",
        "\n",
        "for i in range(0,len(text)):\n",
        "    txt = ' '.join(word for word in text[i] .split() if not word.startswith('https:'))\n",
        "    data_set.at[i, 'text2']= txt\n",
        "    \n",
        "data_set.drop_duplicates('text2', inplace=True)\n",
        "data_set.reset_index(drop = True, inplace=True)\n",
        "data_set.drop('text', axis = 1, inplace = True)\n",
        "data_set.rename(columns={'text2': 'text'}, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hcTE_jcuF1h"
      },
      "source": [
        "text = data_set[\"text\"]\n",
        "\n",
        "for i in range(0,len(text)):\n",
        "    textB = TextBlob(text[i])\n",
        "    sentiment = textB.sentiment.polarity\n",
        "    data_set.at[i, 'Sentiment'] =sentiment\n",
        "    if sentiment <0.00:\n",
        "        SentimentClass = 'Negative'\n",
        "        data_set.at[i, 'SentimentClass'] = SentimentClass \n",
        "    elif sentiment >0.00:\n",
        "        SentimentClass = 'Positive'\n",
        "        data_set.at[i, 'SentimentClass']= SentimentClass \n",
        "    else:\n",
        "        SentimentClass = 'Neutral'\n",
        "        data_set.at[i, 'SentimentClass']= SentimentClass "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGlV4fMVueFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30b6644-e0c6-477c-f835-121ca94ff108"
      },
      "source": [
        "print(textB)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@awkward_duck @MsBraxtonTweets Video - BLM AT SCHOOL Black Lives Matter at School Â· Racial Justice\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKwoIM17yJRl"
      },
      "source": [
        "data_set.to_csv(\"/content/drive/MyDrive/Colab Notebooks/BLM1-1.csv\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN4TJL6zrBcc"
      },
      "source": [
        "Htag_df = pd.DataFrame()\n",
        "j = 0\n",
        "\n",
        "for tweet in range(0,len(results)):\n",
        "    hashtag = results[tweet].entities.get('hashtags')\n",
        "    for i in range(0,len(hashtag)):\n",
        "        Htag = hashtag[i]['text'] \n",
        "        Htag_df.at[j, 'Hashtag']= Htag\n",
        "        j = j+1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m1tUIXWtlaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22357127-ae1a-4def-d22b-943c2ea628fd"
      },
      "source": [
        "print(Htag_df)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          Hashtag\n",
            "0                        PS5Share\n",
            "1    MarvelsSpiderManMilesMorales\n",
            "2              RhythminTheMorning\n",
            "3              WhereHitMusicLives\n",
            "4                BlackLivesMatter\n",
            "..                            ...\n",
            "187                        MLKDay\n",
            "188                        MLKDay\n",
            "189                           BLM\n",
            "190                           OtD\n",
            "191                           OtD\n",
            "\n",
            "[192 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uesT4UgzJxF"
      },
      "source": [
        "Htag_wordcloud = Htag_df.groupby('Hashtag').size()"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}